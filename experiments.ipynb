{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1271dc",
   "metadata": {},
   "source": [
    "<h4>Transfer Learning</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff269",
   "metadata": {},
   "source": [
    "<h5>Imports</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "470aa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote_plus\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Input, Dropout\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "import jsonlines\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from typing import Callable\n",
    "from sklearn import svm\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.python.profiler import profiler_v2 as profiler\n",
    "import visualkeras\n",
    "from PIL import ImageFont\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "751e81ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 19:43:26.105114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a  / a / a  { \"a-a\": \"a-a,a-a\", \"a\": \"a / a,a / a a,a / a;a = n.n,a / a,a / a,* / *;a = n.n\", \"a-a\": \"a;a = n.n, a;a = n.n, *;a = n.n\", \"a-a\": \"a / n.n  ( a a n.n; x; x )  a / n.n  ( a, a a )  a / n.n.n.n a / n.n a / n.n.n.n\", \"a\": \"a = x; a = x\" } ' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 19:43:26.380897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a   / a / a   { \" a - a \" :   \" a - a , a - a \" ,   \" a \" :   \" a / a , a / a   a , a / a ; a = n . n , a / a , a / a , * / * ; a = n . n \" ,   \" a - a \" :   \" a ; a = n . n ,   a ; a = n . n ,   * ; a = n . n \" ,   \" a - a \" :   \" a / n . n   ( a   a   n . n ;   x ;   x )   a / n . n   ( a ,   a   a )   a / n . n . n . n   a / n . n   a / n . n . n . n \" ,   \" a \" :   \" a = x ;   a = x \" } ' 0\n"
     ]
    }
   ],
   "source": [
    "file_names=['malicious','normal']\n",
    "for name in file_names:\n",
    "    data=[]\n",
    "    with jsonlines.open('dataset/'+name+'.txt') as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data.append({'request':{'method':'POST', 'uri':line['request']['uri'], 'body':line['request']['body'],'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "            else:\n",
    "                data.append({'request':{'method':'GET', 'uri':line['request']['uri'], 'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "    with jsonlines.open('dataset/'+name+'_clean.txt', mode='w') as writer:\n",
    "        writer.write_all(data)\n",
    "        \n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "file_names = ['dataset/malicious_clean.txt' ,'dataset/normal_clean.txt']\n",
    "data={}\n",
    "for file in file_names:\n",
    "    data[file]=[]\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data[file].append('POST'+' '+line['request']['uri']+' '+line['request']['body']+' '+json.dumps(line['request']['headers']))\n",
    "            else:\n",
    "                data[file].append('GET'+' '+line['request']['uri']+' '+json.dumps(line['request']['headers']))\n",
    "\n",
    "   \n",
    "                \n",
    "normal = data[file_names[1]]\n",
    "malicious = data[file_names[0]]\n",
    "normal_part1 = normal[180000:]\n",
    "normal_part2 = normal[:180000]\n",
    "\n",
    "train_examples = normal_part2\n",
    "test_examples = normal_part1+malicious\n",
    "train_labels = [0] * len(train_examples)\n",
    "test_labels = [0]* len(normal_part1)\n",
    "test_labels.extend([1] * len(malicious))\n",
    "\n",
    "\n",
    "\n",
    "# add shuffled malicious data to train set\n",
    "#malicious_shuffled = malicious.copy()  \n",
    "#np.random.shuffle(malicious_shuffled)\n",
    "#train_examples.extend(malicious_shuffled[:50000])\n",
    "#train_labels.extend([1] * len(malicious_shuffled[:50000]))\n",
    "\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),train_examples)), train_labels))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),test_examples)), test_labels))\n",
    "\n",
    "#shuflee datasets with given radnom seed\n",
    "dataset_train = dataset_train.shuffle(400000, seed=42, reshuffle_each_iteration=False)\n",
    "dataset_test = dataset_test.shuffle(400000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "def preprocess_text(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    text = tf.strings.regex_replace(text, '(.)',  r'\\1 ')\n",
    "    return text, label\n",
    "\n",
    "def preprocess_text_substitution(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    " \n",
    "# Map the preprocess function to the dataset\n",
    "train = dataset_train.map(preprocess_text)\n",
    "test = dataset_test.map(preprocess_text)\n",
    "\n",
    "train_sub = dataset_train.map(preprocess_text_substitution)\n",
    "test_sub = dataset_test.map(preprocess_text_substitution)\n",
    "\n",
    "for text, label in train_sub.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "for text, label in train.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d237b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c74ffdfb",
   "metadata": {},
   "source": [
    "<h4>Save and load vectorization from disk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d89fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from_disk = pickle.load(open(\"vectorization.pkl\", \"rb\"))\n",
    "vectorization = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "from_disk_sub = pickle.load(open(\"vectorization_sub.pkl\", \"rb\"))\n",
    "vectorization_sub = TextVectorization.from_config(from_disk_sub['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization_sub.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization_sub.set_weights(from_disk_sub['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cf1bf",
   "metadata": {},
   "source": [
    "<h4>Load and retrain all models</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0531230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load lstm model\n",
    "lstm_model = tf.keras.models.load_model('lstm/my_model')\n",
    "lstm_model_sub = tf.keras.models.load_model('lstm_sub/my_model')\n",
    "\n",
    "#load transformer model\n",
    "transformer_model = tf.keras.models.load_model('trans/my_model')\n",
    "transformer_model_sub = tf.keras.models.load_model('trans_sub/my_model')\n",
    "\n",
    "#load cnn model\n",
    "cnn_model = tf.keras.models.load_model('cnn/my_model') \n",
    "cnn_model_sub = tf.keras.models.load_model('cnn_sub/my_model') \n",
    "\n",
    "#load autoencoder model\n",
    "autoencoder_model = tf.keras.models.load_model('autoencoder/my_model')\n",
    "autoencoder_model_sub = tf.keras.models.load_model('autoencoder_sub/my_model')\n",
    "\n",
    "import pickle\n",
    "filename = './svm/svm_model.sav'\n",
    "svm_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename_sub = './svm_sub/svm_model.sav'\n",
    "svm_model_sub = pickle.load(open(filename_sub, 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85f91fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 00:49:05.358997: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [117899]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "/tmp/ipykernel_6549/3238461473.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_auto_svm = np.array(list(test_auto.as_numpy_iterator()))\n",
      "2023-06-07 00:49:29.463953: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype resource\n",
      "\t [[{{node Placeholder/_9}}]]\n",
      "/tmp/ipykernel_6549/3238461473.py:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_auto_sub_svm = np.array(list(test_auto_sub.as_numpy_iterator()))\n"
     ]
    }
   ],
   "source": [
    "#testdataset for normal_models:\n",
    "def sub_processing(text, label):\n",
    "    return  vectorization_sub(text), label\n",
    "\n",
    "def processing(text, label):\n",
    "    return  vectorization(text), label\n",
    "test_auto_sub = test_sub.map(sub_processing)\n",
    "\n",
    "test_auto = test.map(processing)\n",
    "\n",
    "\n",
    "\n",
    "#tesdataset for svm\n",
    "test_auto_svm = np.array(list(test_auto.as_numpy_iterator()))\n",
    "test_auto_sub_svm = np.array(list(test_auto_sub.as_numpy_iterator()))\n",
    "test_text = test_auto_svm[:,0]\n",
    "test_label = test_auto_svm[:,1]\n",
    "test_text_sub = test_auto_sub_svm[:,0]\n",
    "test_label_sub = test_auto_sub_svm[:,1]\n",
    "\n",
    "\n",
    "test_auto_sub = test_auto_sub.batch(32)\n",
    "test_auto = test_auto.batch(32)\n",
    "def get_data(x, y):\n",
    "  return x\n",
    "\n",
    "# Use the map() function to extract the labels\n",
    "dataset_tmp = test_auto.map(get_data)\n",
    "dataset_tmp_sub = test_auto_sub.map(get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9868826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for cnn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 19:44:46.424808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype resource\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predictions: 22.72735857963562 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 19:45:09.144592: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype resource\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sub predictions: 21.249239444732666 seconds\n",
      "Suma trenowalnych parametrów: 192545\n",
      "Suma trenowalnych parametrów sub: 160161\n",
      "Running predictions for transformer\n",
      "Model predictions: 22.944324016571045 seconds\n",
      "Model sub predictions: 22.16677451133728 seconds\n",
      "Suma trenowalnych parametrów: 71777\n",
      "Suma trenowalnych parametrów sub: 67681\n",
      "Running predictions for lstm\n",
      "Model predictions: 49.38928747177124 seconds\n",
      "Model sub predictions: 32.75259304046631 seconds\n",
      "Suma trenowalnych parametrów: 620321\n",
      "Suma trenowalnych parametrów sub: 604321\n",
      "Running predictions for autoencoder\n",
      "Model predictions: 22.603391885757446 seconds\n",
      "Model sub predictions: 21.303611516952515 seconds\n",
      "Suma trenowalnych parametrów: 148288\n",
      "Suma trenowalnych parametrów sub: 37280\n",
      "Running predictions for svm\n",
      "Model predictions: 2187.1206471920013 seconds\n",
      "Model sub predictions: 1154.9324202537537 seconds\n"
     ]
    }
   ],
   "source": [
    "#run and time predictions\n",
    "def predict_and_time(model,model_sub,name):\n",
    "    print(f\"Running predictions for {name}\")\n",
    "    start_time = time.time()\n",
    "    reconstructions = model.predict(test_auto, verbose=0)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Model predictions: {elapsed_time} seconds\")\n",
    "    start_time = time.time()\n",
    "    reconstructions_sub = model_sub.predict(test_auto_sub, verbose=0)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Model sub predictions: {elapsed_time} seconds\")\n",
    "    trainable_params = int(np.sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]))\n",
    "    print(\"Suma trenowalnych parametrów:\", trainable_params)\n",
    "    trainable_params = int(np.sum([tf.keras.backend.count_params(w) for w in model_sub.trainable_weights]))\n",
    "    print(\"Suma trenowalnych parametrów sub:\", trainable_params)\n",
    "    return reconstructions, reconstructions_sub\n",
    "def predict_and_time_svm(model,model_sub):\n",
    "    print(f\"Running predictions for svm\")\n",
    "    start_time = time.time()\n",
    "    reconstructions = model.predict(list(test_text))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Model predictions: {elapsed_time} seconds\")\n",
    "    start_time = time.time()\n",
    "    reconstructions_sub = model_sub.predict(list(test_text_sub))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Model sub predictions: {elapsed_time} seconds\")\n",
    "    return reconstructions, reconstructions_sub    \n",
    "\n",
    "reconstructions_cnn, reconstructions_sub_cnn = predict_and_time(cnn_model,cnn_model_sub,\"cnn\")\n",
    "reconstructions_trans, reconstructions_sub_trans = predict_and_time(transformer_model,transformer_model_sub,\"transformer\")\n",
    "reconstructions_lstm, reconstructions_sub_lstm = predict_and_time(lstm_model,lstm_model_sub,\"lstm\")\n",
    "reconstructions_auto, reconstructions_sub_auto = predict_and_time(autoencoder_model,autoencoder_model_sub,\"autoencoder\")\n",
    "reconstructions_svm, reconstructions_sub_svm = predict_and_time_svm(svm_model,svm_model_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05b15cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the lists to disk\n",
    "with open('reconstructions_cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_cnn, f)\n",
    "\n",
    "with open('reconstructions_sub_cnn.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_sub_cnn, f)\n",
    "\n",
    "with open('reconstructions_trans.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_trans, f)\n",
    "\n",
    "with open('reconstructions_sub_trans.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_sub_trans, f)\n",
    "\n",
    "with open('reconstructions_lstm.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_lstm, f)\n",
    "\n",
    "with open('reconstructions_sub_lstm.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_sub_lstm, f)\n",
    "\n",
    "with open('reconstructions_auto.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_auto, f)\n",
    "\n",
    "with open('reconstructions_sub_auto.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_sub_auto, f)\n",
    "\n",
    "with open('reconstructions_svm.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_svm, f)\n",
    "\n",
    "with open('reconstructions_sub_svm.pkl', 'wb') as f:\n",
    "    pickle.dump(reconstructions_sub_svm, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c01d3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Load the lists from disk\n",
    "with open('reconstructions_cnn.pkl', 'rb') as f:\n",
    "    reconstructions_cnn = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_sub_cnn.pkl', 'rb') as f:\n",
    "    reconstructions_sub_cnn = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_trans.pkl', 'rb') as f:\n",
    "    reconstructions_trans = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_sub_trans.pkl', 'rb') as f:\n",
    "    reconstructions_sub_trans = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_lstm.pkl', 'rb') as f:\n",
    "    reconstructions_lstm = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_sub_lstm.pkl', 'rb') as f:\n",
    "    reconstructions_sub_lstm = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_auto.pkl', 'rb') as f:\n",
    "    reconstructions_auto = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_sub_auto.pkl', 'rb') as f:\n",
    "    reconstructions_sub_auto = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_svm.pkl', 'rb') as f:\n",
    "    reconstructions_svm = pickle.load(f)\n",
    "\n",
    "with open('reconstructions_sub_svm.pkl', 'rb') as f:\n",
    "    reconstructions_sub_svm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "073354ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model cnn\n",
      "Accuracy: 0.8381496026259765\n",
      "Precision: 0.9997620782465166\n",
      "Recall: 0.7790704411406852\n",
      "F1 Score: 0.8757261572928334\n",
      "MCC: 0.6966396092483333\n",
      "Metrics for model cnn_sub\n",
      "Accuracy: 0.9203470767351716\n",
      "Precision: 0.9979282125653908\n",
      "Recall: 0.8930346817460225\n",
      "F1 Score: 0.9425721746255968\n",
      "MCC: 0.8274001154686692\n",
      "Metrics for model trans\n",
      "Accuracy: 0.9121790685247543\n",
      "Precision: 0.9851041813048533\n",
      "Recall: 0.8935329493968643\n",
      "F1 Score: 0.9370868170328601\n",
      "MCC: 0.8032607686952989\n",
      "Metrics for model trans_sub\n",
      "Accuracy: 0.929286932035047\n",
      "Precision: 0.9972066326530612\n",
      "Recall: 0.9059317025689753\n",
      "F1 Score: 0.9493803848232228\n",
      "MCC: 0.8436371037142679\n",
      "Metrics for model lstm\n",
      "Accuracy: 0.8873272886114386\n",
      "Precision: 0.9992888305365226\n",
      "Recall: 0.8466726149781574\n",
      "F1 Score: 0.9166718940144777\n",
      "MCC: 0.7711872941351099\n",
      "Metrics for model lstm_sub\n",
      "Accuracy: 0.9423913688835359\n",
      "Precision: 0.9978085828418297\n",
      "Recall: 0.9233247198692917\n",
      "F1 Score: 0.9591227521124727\n",
      "MCC: 0.869560969586339\n",
      "tf.Tensor(11.465675, shape=(), dtype=float32)\n",
      "Metrics for model auto\n",
      "Accuracy: 0.8067074360257509\n",
      "Precision: 0.9201174820733998\n",
      "Recall: 0.8058957809476356\n",
      "F1 Score: 0.8592272292059179\n",
      "MCC: 0.5677232758071605\n",
      "tf.Tensor(24.303844, shape=(), dtype=float32)\n",
      "Metrics for model auto_sub\n",
      "Accuracy: 0.42362530640633084\n",
      "Precision: 0.9919549477071601\n",
      "Recall: 0.21431302796092655\n",
      "F1 Score: 0.35247370025918584\n",
      "MCC: 0.2543972680056094\n",
      "Metrics for model svm\n",
      "Accuracy: 0.8196676816597257\n",
      "Precision: 0.8221106224493839\n",
      "Recall: 0.9617376794632615\n",
      "F1 Score: 0.8864596405970468\n",
      "MCC: 0.49674785252946285\n",
      "Metrics for model svm_sub\n",
      "Accuracy: 0.8185820066327959\n",
      "Precision: 0.8193321132691815\n",
      "Recall: 0.9649242749046918\n",
      "F1 Score: 0.886188162802701\n",
      "MCC: 0.49301431600324186\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m calc_and_print_metrics(actual,reconstructions_svm,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m,pred_treshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m     71\u001b[0m calc_and_print_metrics(actual,reconstructions_sub_svm,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm_sub\u001b[39m\u001b[38;5;124m\"\u001b[39m,pred_treshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mprint_prec_recall_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreconstructions_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreconstructions_sub_cnn\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcnn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m print_prec_recall_curve(reconstructions_trans,reconstructions_sub_trans,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrans\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m print_prec_recall_curve(reconstructions_lstm,reconstructions_sub_lstm,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[82], line 50\u001b[0m, in \u001b[0;36mprint_prec_recall_curve\u001b[0;34m(reconsturctions, reconsturctions_sub, name, mse_ratio)\u001b[0m\n\u001b[1;32m     47\u001b[0m     avg \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28msum\u001b[39m(mse) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(mse)\n\u001b[1;32m     48\u001b[0m     reconsturctions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: sigmoid(x\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m-\u001b[39mmse_ratio\u001b[38;5;241m*\u001b[39mavg\u001b[38;5;241m.\u001b[39mnumpy()), \u001b[38;5;28mlist\u001b[39m(mse)))\n\u001b[0;32m---> 50\u001b[0m precision, recall, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(\u001b[43my_test\u001b[49m, reconsturctions)\n\u001b[1;32m     51\u001b[0m precision_sub, recall_sub, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(y_test, reconsturctions_sub)\n\u001b[1;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(recall, precision)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def calc_and_print_metrics(y_test,reconsturctions,name, mse_ratio=0.5,pred_treshold=0.5):\n",
    "    \n",
    "    if(name.find(\"auto\") != -1):\n",
    "        if(name.find(\"sub\") != -1):\n",
    "            tmp_sub = np.concatenate(list(dataset_tmp_sub.as_numpy_iterator()))\n",
    "            mse_ = tf.keras.losses.mean_squared_error(tmp_sub, reconsturctions)\n",
    "            mse = [0.01*x for x in mse_]\n",
    "        else:  \n",
    "            tmp = np.concatenate(list(dataset_tmp.as_numpy_iterator()))\n",
    "            mse = tf.keras.losses.mean_squared_error(tmp, reconsturctions)\n",
    "        avg =  sum(mse) / len(mse)\n",
    "        print(avg)\n",
    "        reconsturctions=list(map(lambda x: sigmoid(x.numpy()-mse_ratio*avg.numpy()), list(mse)))\n",
    "        y_pred = list(map(lambda x: 0 if sigmoid(x.numpy()-mse_ratio*avg.numpy())<pred_treshold else 1, list(mse)))\n",
    "    elif(name.find(\"svm\") != -1):\n",
    "        y_pred = list(map(lambda x: 1 if x==-1 else 0, list(reconsturctions)))\n",
    "    else:\n",
    "        y_pred = list(map(lambda x: 0 if x[0]<pred_treshold else 1, list(reconsturctions)))\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Metrics for model {name}\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"MCC:\", mcc)\n",
    "\n",
    "    \n",
    "def print_prec_recall_curve(y_test,reconsturctions,reconsturctions_sub,name, mse_ratio=0.5):\n",
    "     \n",
    "    if(name.find(\"auto\") != -1):\n",
    "        tmp_sub = np.concatenate(list(dataset_tmp_sub.as_numpy_iterator()))\n",
    "        mse_ = tf.keras.losses.mean_squared_error(tmp_sub, reconsturctions_sub)\n",
    "        mse = [0.01*x for x in mse_]\n",
    "        avg =  sum(mse) / len(mse)\n",
    "        reconsturction_subs=list(map(lambda x: sigmoid(x.numpy()-mse_ratio*avg.numpy()), list(mse)))\n",
    "        tmp = np.concatenate(list(dataset_tmp.as_numpy_iterator()))\n",
    "        mse = tf.keras.losses.mean_squared_error(tmp, reconsturctions)\n",
    "        avg =  sum(mse) / len(mse)\n",
    "        reconsturctions=list(map(lambda x: sigmoid(x.numpy()-mse_ratio*avg.numpy()), list(mse)))\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, reconsturctions)\n",
    "    precision_sub, recall_sub, _ = precision_recall_curve(y_test, reconsturctions_sub)\n",
    "    plt.plot(recall, precision)\n",
    "    plt.plot(recall_sub, precision_sub)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "#actual = test_auto.map(lambda x,y:y)\n",
    "#actual = np.concatenate(list(actual.as_numpy_iterator()))\n",
    "calc_and_print_metrics(actual,reconstructions_cnn,\"cnn\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_sub_cnn,\"cnn_sub\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_trans,\"trans\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_sub_trans,\"trans_sub\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_lstm,\"lstm\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_sub_lstm,\"lstm_sub\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_auto,\"auto\",0.3)\n",
    "calc_and_print_metrics(actual,reconstructions_sub_auto,\"auto_sub\", 0.3)\n",
    "calc_and_print_metrics(actual,reconstructions_svm,\"svm\",pred_treshold=0.1)\n",
    "calc_and_print_metrics(actual,reconstructions_sub_svm,\"svm_sub\",pred_treshold=0.1)\n",
    "\n",
    "print_prec_recall_curve(actual,reconstructions_cnn,reconstructions_sub_cnn,\"cnn\")\n",
    "print_prec_recall_curve(actual,reconstructions_trans,reconstructions_sub_trans,\"trans\")\n",
    "print_prec_recall_curve(actual,reconstructions_lstm,reconstructions_sub_lstm,\"lstm\")\n",
    "print_prec_recall_curve(actual,reconstructions_auto,reconstructions_sub_auto,\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3daa35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO \n",
    "import sys\n",
    "\n",
    "class Capturing(list):\n",
    "    def __enter__(self):\n",
    "        self._stdout = sys.stdout\n",
    "        sys.stdout = self._stringio = StringIO()\n",
    "        return self\n",
    "    def __exit__(self, *args):\n",
    "        self.extend(self._stringio.getvalue().splitlines())\n",
    "        del self._stringio    # free up some memory\n",
    "        sys.stdout = self._stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb2db988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for model cnn\n",
      "Accuracy: 0.8381496026259765\n",
      "Precision: 0.9997620782465166\n",
      "Recall: 0.7790704411406852\n",
      "F1 Score: 0.8757261572928334\n",
      "MCC: 0.6966396092483333\n",
      "\n",
      "Metrics for model cnn_sub\n",
      "Accuracy: 0.9203470767351716\n",
      "Precision: 0.9979282125653908\n",
      "Recall: 0.8930346817460225\n",
      "F1 Score: 0.9425721746255968\n",
      "MCC: 0.8274001154686692\n",
      "cnn & Accuracy: 0.84 & Precision: 1.00 & Recall: 0.78 & F1 Score: 0.88 & MCC: 0.70 \\\\\n",
      "cnn_sub & Accuracy: 0.92 & Precision: 1.00 & Recall: 0.89 & F1 Score: 0.94 & MCC: 0.83 \\\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_latex_table_row(model_name, metrics):\n",
    "    # Create the LaTeX table row template\n",
    "    table_row = f\"{model_name} & \"\n",
    "\n",
    "    # Append the metrics to the table row\n",
    "    for key, value in metrics.items():\n",
    "        table_row += f\"{key}: {value:.2f} & \"\n",
    "\n",
    "    # Remove the trailing '&' character and add the table row ending\n",
    "    table_row = table_row.rstrip(\" & \") + \" \\\\\\\\\"\n",
    "\n",
    "    return table_row\n",
    "\n",
    "def parse_metrics_input(input_string):\n",
    "    # Split the input string into lines\n",
    "    lines = input_string.split(\"\\n\")\n",
    "\n",
    "    # Initialize variables\n",
    "    model_name = None\n",
    "    metrics = {}\n",
    "\n",
    "    # Parse the input lines\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        if line.startswith(\"Metrics for model\"):\n",
    "            # Extract the model name from the line\n",
    "            model_name = line.split(\" \")[-1]\n",
    "        elif \":\" in line:\n",
    "            # Split the line into metric name and value\n",
    "            metric_name, metric_value = line.split(\":\")\n",
    "            metric_name = metric_name.strip()\n",
    "            metric_value = float(metric_value.strip())\n",
    "\n",
    "            # Add the metric to the dictionary\n",
    "            metrics[metric_name] = metric_value\n",
    "    \n",
    "    return model_name, metrics\n",
    "\n",
    "input_string = \"\"\"\n",
    "Metrics for model cnn\n",
    "Accuracy: 0.8381496026259765\n",
    "Precision: 0.9997620782465166\n",
    "Recall: 0.7790704411406852\n",
    "F1 Score: 0.8757261572928334\n",
    "MCC: 0.6966396092483333\n",
    "Metrics for model cnn_sub\n",
    "Accuracy: 0.9203470767351716\n",
    "Precision: 0.9979282125653908\n",
    "Recall: 0.8930346817460225\n",
    "F1 Score: 0.9425721746255968\n",
    "MCC: 0.8274001154686692\n",
    "\"\"\"\n",
    "metric_sections = input_string.strip().split(\"Metrics for model\")\n",
    "\n",
    "# Process each metric section and generate the LaTeX table rows\n",
    "table_rows = []\n",
    "for metric_section in metric_sections[1:]:\n",
    "    model_name, metrics = parse_metrics_input(\"Metrics for model\" + metric_section)\n",
    "    table_row = generate_latex_table_row(model_name, metrics)\n",
    "    table_rows.append(table_row)\n",
    "\n",
    "# Print the generated LaTeX table rows\n",
    "for row in table_rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dfd905c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf7b515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25065"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(malicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff997d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
