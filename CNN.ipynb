{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1271dc",
   "metadata": {},
   "source": [
    "<h4>TextCNN</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff269",
   "metadata": {},
   "source": [
    "<h5>Imports</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "470aa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote_plus\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Input, Dropout\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "import jsonlines\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from typing import Callable\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9975964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loda all payloads from txt files in dataset folder (where each payload is one line)\n",
    "def load_payloads(dataset_path: str) -> list:\n",
    "    payloads = []\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        with open(dataset_path + filename, 'r') as f:\n",
    "            payloads.extend(f.readlines())\n",
    "    return payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d237b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=['malicious','normal']\n",
    "for name in file_names:\n",
    "    data=[]\n",
    "    with jsonlines.open('dataset/'+name+'.txt') as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data.append({'request':{'method':'POST', 'uri':line['request']['uri'], 'body':line['request']['body'],'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "            else:\n",
    "                data.append({'request':{'method':'GET', 'uri':line['request']['uri'], 'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "    with jsonlines.open('dataset/'+name+'_clean.txt', mode='w') as writer:\n",
    "        writer.write_all(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c0852",
   "metadata": {},
   "source": [
    "<h4>Load and create datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c294e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:21:07.400742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [211600]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a  / a / a-a  { \"a-a\": \"a-a\", \"a\": \"a / a,a / a a,a / a;a = n.n,a / a,a / a,* / *;a = n.n\", \"a-a\": \"a\", \"a-a\": \"a / n.n  ( a; a a a a n_n_n )  a / n.n  ( a, a a )  a / n.n.n.n a / n.n\", \"a\": \"a = x; a = x\" } ' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:21:07.616136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [211600]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a   / a / a - a   { \" a - a \" :   \" a - a \" ,   \" a \" :   \" a / a , a / a   a , a / a ; a = n . n , a / a , a / a , * / * ; a = n . n \" ,   \" a - a \" :   \" a \" ,   \" a - a \" :   \" a / n . n   ( a ;   a   a   a   a   n _ n _ n )   a / n . n   ( a ,   a   a )   a / n . n . n . n   a / n . n \" ,   \" a \" :   \" a = x ;   a = x \" } ' 0\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "file_names = ['dataset/malicious_clean.txt' ,'dataset/normal_clean.txt']\n",
    "data={}\n",
    "for file in file_names:\n",
    "    data[file]=[]\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data[file].append('POST'+' '+line['request']['uri']+' '+line['request']['body']+' '+json.dumps(line['request']['headers']))\n",
    "            else:\n",
    "                data[file].append('GET'+' '+line['request']['uri']+' '+json.dumps(line['request']['headers']))\n",
    "\n",
    "payloads = load_payloads('dataset/payloads/')      \n",
    "                \n",
    "normal = data[file_names[1]]\n",
    "malicious = data[file_names[0]]\n",
    "normal_part1 = normal[180000:]\n",
    "normal_part2 = normal[:180000]\n",
    "\n",
    "train_examples = normal_part2\n",
    "test_examples = normal_part1+malicious\n",
    "train_labels = [0] * len(train_examples)\n",
    "test_labels = [0]* len(normal_part1)\n",
    "test_labels.extend([1] * len(malicious))\n",
    "\n",
    "payload_iterator={}\n",
    "payload_iterator[0] = 0\n",
    "def get_next_payload():\n",
    "    payload_iterator[0] = (payload_iterator[0] + 1) % len(payloads)\n",
    "    return payloads[payload_iterator[0]]\n",
    "\n",
    "#create synthetic malicious data by adding payloads to normal data (PAYLOAD SHOULD BE injected at a space character )\n",
    "tmp = normal_part1.copy()\n",
    "np.random.shuffle(payloads)\n",
    "synthetic_malicious = []\n",
    "for i in range(len(tmp)):\n",
    "    payload = get_next_payload()\n",
    "    tmp[i] = tmp[i].split(' ') \n",
    "    tmp[i].insert(np.random.randint(0,len(tmp[i])), payload)\n",
    "    tmp[i] = ' '.join(tmp[i])\n",
    "    synthetic_malicious.append(tmp[i])\n",
    "\n",
    "\n",
    "# add shuffled malicious data to train set\n",
    "#malicious_shuffled = malicious.copy()  \n",
    "#np.random.shuffle(malicious_shuffled)\n",
    "#train_examples.extend(malicious_shuffled[:50000])\n",
    "#train_labels.extend([1] * len(malicious_shuffled[:50000]))\n",
    "\n",
    "train_examples.extend(synthetic_malicious)\n",
    "train_labels.extend([1] * len(synthetic_malicious))\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),train_examples)), train_labels))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),test_examples)), test_labels))\n",
    "\n",
    "#shuflee datasets with given radnom seed\n",
    "dataset_train = dataset_train.shuffle(400000, seed=42, reshuffle_each_iteration=False)\n",
    "dataset_test = dataset_test.shuffle(400000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "def preprocess_text(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    text = tf.strings.regex_replace(text, '(.)',  r'\\1 ')\n",
    "    return text, label\n",
    "\n",
    "def preprocess_text_substitution(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    " \n",
    "# Map the preprocess function to the dataset\n",
    "train = dataset_train.map(preprocess_text)\n",
    "test = dataset_test.map(preprocess_text)\n",
    "\n",
    "train_sub = dataset_train.map(preprocess_text_substitution)\n",
    "test_sub = dataset_test.map(preprocess_text_substitution)\n",
    "\n",
    "for text, label in train_sub.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "for text, label in train.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b6ec31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WWWWW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9246d4",
   "metadata": {},
   "source": [
    "<h4>Vocabularies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e08cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 00:43:23.850876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-23 00:53:16.487408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorization = TextVectorization(\n",
    "    max_tokens=1000,\n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=256,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization_sub = TextVectorization(\n",
    "    max_tokens=5000, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=128,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization.adapt(train.map(lambda x, y: x))\n",
    "vectorization_sub.adapt(train_sub.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ffdfb",
   "metadata": {},
   "source": [
    "<h4>Save and load vectorization from disk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43d89fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 07:48:35.871099: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-13 07:48:36.032873: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump({'config': vectorization.get_config(),'weights': vectorization.get_weights()}, open(\"vectorization.pkl\", \"wb\"))\n",
    "\n",
    "#pickle.dump({'config': vectorization_sub.get_config(), 'weights': vectorization_sub.get_weights()}, open(\"vectorization_sub.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "from_disk = pickle.load(open(\"vectorization.pkl\", \"rb\"))\n",
    "vectorization = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "from_disk_sub = pickle.load(open(\"vectorization_sub.pkl\", \"rb\"))\n",
    "vectorization_sub = TextVectorization.from_config(from_disk_sub['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization_sub.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization_sub.set_weights(from_disk_sub['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cf1bf",
   "metadata": {},
   "source": [
    "<h4>CNN</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0531230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 09:21:32.105319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype int64\n",
      "\t [[{{node Placeholder/_10}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6613/6613 [==============================] - 49s 7ms/step - loss: 0.0398\n",
      "Epoch 2/10\n",
      "6613/6613 [==============================] - 47s 7ms/step - loss: 0.0086\n",
      "Epoch 3/10\n",
      "6613/6613 [==============================] - 48s 7ms/step - loss: 0.0049\n",
      "Epoch 4/10\n",
      "6613/6613 [==============================] - 49s 7ms/step - loss: 0.0036\n",
      "Epoch 5/10\n",
      "6613/6613 [==============================] - 47s 7ms/step - loss: 0.0027\n",
      "Epoch 6/10\n",
      "6613/6613 [==============================] - 52s 8ms/step - loss: 0.0023\n",
      "Epoch 7/10\n",
      "6613/6613 [==============================] - 68s 10ms/step - loss: 0.0019\n",
      "Epoch 8/10\n",
      " 519/6613 [=>............................] - ETA: 49s - loss: 0.0025"
     ]
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 4)\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "\n",
    "\n",
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), label\n",
    "\n",
    "train_auto = train_sub.map(autoencoder_processing)\n",
    "\n",
    "train_auto = train_auto.batch(32)\n",
    "# Define the autoencoder model\n",
    "input_layer = tf.keras.layers.Input(shape=(256,))\n",
    "mod = embedding_layer(input_layer)\n",
    "mod =  layers.Conv1D(128, 16, activation='relu', padding='same')(mod)\n",
    "mod = layers.MaxPooling1D(16, padding='same')(mod)\n",
    "mod =  layers.Conv1D(128, 8, activation='relu', padding='same')(mod)\n",
    "mod = layers.MaxPooling1D(8, padding='same')(mod)\n",
    "mod = flatten_layer(mod)\n",
    "mod =  tf.keras.layers.Dense(128, activation='relu')(mod)\n",
    "mod =  tf.keras.layers.Dense(1, activation='sigmoid')(mod)\n",
    "\n",
    "cnn = tf.keras.models.Model(input_layer, mod)\n",
    "\n",
    "# Compile and train the model\n",
    "cnn.compile(optimizer='adam',  loss=losses.BinaryCrossentropy())\n",
    "cnn.fit(train_auto, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85f91fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn/my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.fit(train_auto, epochs=10)\n",
    "cnn.save('cnn/my_model')\n",
    "cnn = tf.keras.models.load_model('cnn/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9868826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 08:13:01.780885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_9' with dtype resource\n",
      "\t [[{{node Placeholder/_9}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 24s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), label\n",
    "test_auto = test_sub.map(autoencoder_processing)\n",
    "test_auto = test_auto.batch(32)\n",
    "reconsturctions =  cnn.predict(test_auto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05b15cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       ...,\n",
       "       [1.        ],\n",
       "       [1.        ],\n",
       "       [0.25143528]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconsturctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c01d3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(map(lambda x: 0 if x[0]<0.5 else 1, list(reconsturctions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "073354ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-13 08:15:37.595484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [117899]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "actual =test_auto.map(lambda x,y:y)\n",
    "actual = np.concatenate(list(actual.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3daa35e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9695533294329757"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(actual,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb2db988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd905c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
