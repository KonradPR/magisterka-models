{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1271dc",
   "metadata": {},
   "source": [
    "<h4>TextCNN</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff269",
   "metadata": {},
   "source": [
    "<h5>Imports</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470aa940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:25:57.179712: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-22 21:25:57.278157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 21:25:58.104278: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote_plus\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Input, Dropout\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "import jsonlines\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d237b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=['malicious','normal']\n",
    "for name in file_names:\n",
    "    data=[]\n",
    "    with jsonlines.open('dataset/'+name+'.txt') as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data.append({'request':{'method':'POST', 'uri':line['request']['uri'], 'body':line['request']['body'],'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "            else:\n",
    "                data.append({'request':{'method':'GET', 'uri':line['request']['uri'], 'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "    with jsonlines.open('dataset/'+name+'_clean.txt', mode='w') as writer:\n",
    "        writer.write_all(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c0852",
   "metadata": {},
   "source": [
    "<h4>Load and create datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c294e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:26:16.088135: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:16.271871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:16.271919: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:16.274244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:16.274285: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:16.274303: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:17.216378: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:17.216723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:17.216737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-04-22 21:26:17.216768: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-04-22 21:26:17.216884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a  / a / a / a  { \"a\" = \"a\" }   { \"a-a\": \"a\", \"a\": \"a / a,* / *\", \"a-a\": \"a, a, a\", \"a-a\": \"a / n.n  ( a a n.n; x; x )  a / n.n  ( a, a a )  a / n.n.n.n a / n.n\", \"a\": \"a = x; a = x\" } ' 0\n",
      "b'post  / rest / products / reviews  { \"id\" = \"ajgoztlb\" }   { \"accept-language\": \"de\", \"accept\": \"text / css,* / *\", \"accept-encoding\": \"gzip, deflate, br\", \"user-agent\": \"mozilla / 5.0  ( windows nt 10.0; win64; x64 )  applewebkit / 537.36  ( khtml, like gecko )  chrome / 72.0.3626.121 safari / 537.36\", \"cookie\": \"phpsessid = 33ptq3esqvyehncdmubiygychvpzr7gw; continuecode = 8dywbdjgirzm76ncpx2hf8kbrclgrd76\" } ' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:26:19.186871: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-22 21:26:19.214642: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['dataset/malicious_clean.txt' ,'dataset/normal_clean.txt']\n",
    "data={}\n",
    "for file in file_names:\n",
    "    data[file]=[]\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data[file].append('POST'+' '+line['request']['uri']+' '+line['request']['body']+' '+json.dumps(line['request']['headers']))\n",
    "            else:\n",
    "                data[file].append('GET'+' '+line['request']['uri']+' '+json.dumps(line['request']['headers']))\n",
    "                \n",
    "                \n",
    "normal = data[file_names[1]]\n",
    "malicious = data[file_names[0]]\n",
    "normal_part1 = normal[180000:]\n",
    "normal_part2 = normal[:180000]\n",
    "\n",
    "train_examples = normal_part2\n",
    "test_examples = normal_part1+malicious\n",
    "train_labels = [0] * len(train_examples)\n",
    "test_labels = [0]* len(normal_part1)\n",
    "test_labels.extend([1] * len(malicious))\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),train_examples)), train_labels))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),test_examples)), test_labels))\n",
    "\n",
    "\n",
    "def preprocess_text(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    "def preprocess_text_substitution(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    " \n",
    "# Map the preprocess function to the dataset\n",
    "train = dataset_train.map(preprocess_text)\n",
    "test = dataset_test.map(preprocess_text)\n",
    "\n",
    "train_sub = dataset_train.map(preprocess_text_substitution)\n",
    "test_sub = dataset_test.map(preprocess_text_substitution)\n",
    "\n",
    "for text, label in train_sub.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "for text, label in train.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9246d4",
   "metadata": {},
   "source": [
    "<h4>Vocabularies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e08cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:02:03.817092: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-22 21:10:25.488554: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorization = TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=128,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization_sub = TextVectorization(\n",
    "    max_tokens=2000, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=128,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization.adapt(train.map(lambda x, y: x))\n",
    "vectorization_sub.adapt(train_sub.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ffdfb",
   "metadata": {},
   "source": [
    "<h4>Save and load vectorization from disk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d89fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:26:19.285886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-22 21:26:19.435844: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump({'config': vectorization.get_config(),'weights': vectorization.get_weights()}, open(\"vectorization.pkl\", \"wb\"))\n",
    "\n",
    "#pickle.dump({'config': vectorization_sub.get_config(), 'weights': vectorization_sub.get_weights()}, open(\"vectorization_sub.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "from_disk = pickle.load(open(\"vectorization.pkl\", \"rb\"))\n",
    "vectorization = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "from_disk_sub = pickle.load(open(\"vectorization_sub.pkl\", \"rb\"))\n",
    "vectorization_sub = TextVectorization.from_config(from_disk_sub['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization_sub.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization_sub.set_weights(from_disk_sub['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cf1bf",
   "metadata": {},
   "source": [
    "<h4>Autoencoder</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0531230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:26:19.765127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype int64\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2023-04-22 21:26:21.631094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-22 21:26:21.636668: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f8a63bebc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-22 21:26:21.636711: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-04-22 21:26:21.642368: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-22 21:26:21.856032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-04-22 21:26:22.014793: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-22 21:26:22.117100: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 43s 7ms/step - loss: 65.2075\n",
      "Epoch 2/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 45.3778\n",
      "Epoch 3/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 40.7097\n",
      "Epoch 4/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 37.9835\n",
      "Epoch 5/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 36.1523\n",
      "Epoch 6/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 34.5001\n",
      "Epoch 7/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 33.1057\n",
      "Epoch 8/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 32.2520\n",
      "Epoch 9/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 32.4991\n",
      "Epoch 10/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 30.8432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c9876fa60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 4)\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization_sub(text), vectorization_sub(text)\n",
    "\n",
    "train_auto = train_sub.map(autoencoder_processing)\n",
    "\n",
    "train_auto = train_auto.batch(32)\n",
    "# Define the autoencoder model\n",
    "input_layer = tf.keras.layers.Input(shape=(128,))\n",
    "encoder = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
    "encoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(64, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(128, activation='relu')(decoder)\n",
    "autoencoder = tf.keras.models.Model(input_layer, decoder)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam',  loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(train_auto, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85f91fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5625/5625 [==============================] - 41s 7ms/step - loss: 30.0103\n",
      "Epoch 2/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 29.9568\n",
      "Epoch 3/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 29.4605\n",
      "Epoch 4/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 28.9400\n",
      "Epoch 5/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 28.7682\n",
      "Epoch 6/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 27.6316\n",
      "Epoch 7/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 28.1521\n",
      "Epoch 8/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 27.0199\n",
      "Epoch 9/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 28.6628\n",
      "Epoch 10/10\n",
      "5625/5625 [==============================] - 41s 7ms/step - loss: 27.8188\n",
      "INFO:tensorflow:Assets written to: autoencoder/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(train_auto, epochs=10)\n",
    "autoencoder.save('autoencoder/my_model')\n",
    "autoencoder = tf.keras.models.load_model('autoencoder/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9868826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/3685 [..............................] - ETA: 28s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:50:17.787743: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype int64\n",
      "\t [[{{node Placeholder/_7}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 24s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization_sub(text), label\n",
    "test_auto = test_sub.map(autoencoder_processing)\n",
    "test_auto = test_auto.batch(32)\n",
    "reconsturctions =  autoencoder.predict(test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05b15cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 21:50:42.582541: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype string\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    }
   ],
   "source": [
    "def get_data(x, y):\n",
    "  return x\n",
    "\n",
    "# Use the map() function to extract the labels\n",
    "dataset_tmp = test_auto.map(get_data)\n",
    "\n",
    "# Convert the labels dataset to a NumPy array\n",
    "tmp = np.concatenate(list(dataset_tmp.as_numpy_iterator()))\n",
    "mse = tf.keras.losses.mean_squared_error(tmp, reconsturctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c01d3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(117899,), dtype=float32, numpy=\n",
       "array([ 9.091696, 31.913082,  8.286144, ..., 11.511646, 76.687546,\n",
       "       17.263046], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "073354ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'a',\n",
       " '/',\n",
       " '=',\n",
       " '\"a-a\":',\n",
       " '\"a',\n",
       " 'n.n',\n",
       " '(',\n",
       " ')',\n",
       " '\"a\":',\n",
       " 'a,',\n",
       " 'n.n\",',\n",
       " 'x;',\n",
       " '{',\n",
       " '}',\n",
       " 'n.n.n.n',\n",
       " 'x\"',\n",
       " 'a,a',\n",
       " 'x',\n",
       " 'n.n;',\n",
       " 'a,*',\n",
       " '*\",',\n",
       " '*;a',\n",
       " '\"a\",',\n",
       " 'a;a',\n",
       " 'a\",',\n",
       " '\"a,',\n",
       " 'n.n,',\n",
       " '?',\n",
       " 'n.n.n.n\",',\n",
       " '\"a-a,a;a',\n",
       " 'a;',\n",
       " 'n_n_n',\n",
       " 'n.n,a',\n",
       " 'n',\n",
       " '\"a;a',\n",
       " 'a&a',\n",
       " 'a.a',\n",
       " '\"*',\n",
       " '\"a-a\",',\n",
       " '\"a-a,a-a\",',\n",
       " 'n&a',\n",
       " '\"a\":\"a',\n",
       " 'a.*',\n",
       " 'x&a',\n",
       " 'a\",\"a\":\"a',\n",
       " 'a\"',\n",
       " 'a\",\"a\":',\n",
       " 'n,\"a\":\"n\",\"a\":\"n',\n",
       " 'a\",\"a\":\"a\",\"a\":\"a\"',\n",
       " '*',\n",
       " 'a&a-a',\n",
       " \"a'a\",\n",
       " 'n:x\",\"a\":\"n-n-x:n:n.n',\n",
       " 'n:x\"',\n",
       " ',\"a\":\"a\"',\n",
       " '\"a\":n,\"a\":\"a',\n",
       " '\",\"a\":\"n-n-x:n:n.n',\n",
       " 'a-a',\n",
       " 'x@a.a&a',\n",
       " 'a_a_a_a.a',\n",
       " 'a\",\"a\":n,\"a\":\"n\",\"a\":\"n\"',\n",
       " '.',\n",
       " '[',\n",
       " ']',\n",
       " '\"a\"',\n",
       " 'a.',\n",
       " '\"a\":n,\"a\":\"a\",\"a\":n',\n",
       " 'a.\"',\n",
       " '\"a\":\"x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '&a',\n",
       " '\"a\":\"x@a.a\",\"a\":\"a\"',\n",
       " '\"x\"',\n",
       " 'a\",\"a\":\"a\"',\n",
       " 'a:\"',\n",
       " '\"a\":\"n\",\"a\":\"n\",\"a\":\"n\"',\n",
       " 'a\",\"x\"',\n",
       " '\"',\n",
       " 'x&a-a',\n",
       " 'a_a_a_a',\n",
       " 'a_x_x.a',\n",
       " 'a_x',\n",
       " 'a:',\n",
       " '\"a\":\"x\",\"a\":',\n",
       " 'x_x',\n",
       " 'x-x@a.a&a',\n",
       " 'x.x@a.a&a',\n",
       " 'x_x@a.a&a',\n",
       " 'a_a_x.a',\n",
       " 'a@a.a&a',\n",
       " 'a.a.a',\n",
       " 'a_x@a.a&a',\n",
       " 'a.x@a.a&a',\n",
       " 'a-x@a.a&a',\n",
       " 'n&a-a',\n",
       " 'a_a',\n",
       " '>',\n",
       " 'a_a_a.a',\n",
       " '<',\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'x_a@a.a&a',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'n_a',\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'x.a@a.a&a',\n",
       " 'x-a@a.a&a',\n",
       " '\"a\":\"a\",\"a\":',\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'a-a@a.a&a',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"a\"',\n",
       " '-',\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '\"a\":\"a@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'a_a@a.a&a',\n",
       " '\"a\":\"x@a.a\",\"a\":\"x\"',\n",
       " 'a.a@a.a&a',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"a\"',\n",
       " '.a',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"a\"',\n",
       " 'n\"',\n",
       " 'a_a_a_n.a',\n",
       " ',',\n",
       " 'a_n_a_a.a',\n",
       " 'n_a_a_a.a',\n",
       " 'a_x_a_a.a',\n",
       " 'a_a_n_a.a',\n",
       " 'a.x',\n",
       " '.\"',\n",
       " '\"a\":\"x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " 'a_a.a',\n",
       " 'a&#n;a',\n",
       " 'a_a_a',\n",
       " 'x_a_a_a.a',\n",
       " 'a_a_x_a.a',\n",
       " '\"a\":\"x@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'a_x_a.a',\n",
       " '@a',\n",
       " ':\"',\n",
       " '-a',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'a.a.',\n",
       " 'x_a',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"a\"',\n",
       " 'a_a_a,_a.a',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " '_a_a.a',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"a\",\"a\":\"a\",\"a\":',\n",
       " 'a_a_a-a_a.a',\n",
       " ':',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"a\"',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"a\"',\n",
       " 'a_a-a_a_a.a',\n",
       " 'a-a_a_a_a.a',\n",
       " \"'a'\",\n",
       " 'n,',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"a\"',\n",
       " 'a_a_a_a-a.a',\n",
       " 'n.a',\n",
       " 'n.n.n',\n",
       " 'a-a-a',\n",
       " 'a_a_a_x.a',\n",
       " 'a_a_a_n',\n",
       " 'n\",\"a\":\"a\",\"a\":\"a\"',\n",
       " 'a_a,_a_a.a',\n",
       " '$a',\n",
       " 'a!',\n",
       " '&a;a',\n",
       " 'n.',\n",
       " '--a',\n",
       " 'a#',\n",
       " 'a-a:',\n",
       " 'x.a',\n",
       " '+',\n",
       " 'a,\"',\n",
       " 'a-a,',\n",
       " 'a_n',\n",
       " 'a.a\"',\n",
       " 'n_a_a_a',\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"x\"',\n",
       " 'a!\"',\n",
       " \"'a\",\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'a_x_a_a',\n",
       " 'a_n_a_a',\n",
       " 'a’a',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '--',\n",
       " 'a_a_a,_n.a',\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'a...\"',\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"x\"',\n",
       " 'a_a_n_a',\n",
       " 'a_a_a_',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '&a;a&a;',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"x\"',\n",
       " '\"a\":\"a@a.a\",\"a\":\"x\"',\n",
       " 'a&a;',\n",
       " '&#n;a&#n;',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'a_n\"_a_a.a',\n",
       " '&',\n",
       " 'n\",\"a\":\"a',\n",
       " 'a_a_a_n.n.a',\n",
       " 'a:a',\n",
       " 'a._a_a_a.a',\n",
       " \"a'\",\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '_a.a',\n",
       " 'a_n-a_a_a.a',\n",
       " '-&a',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"x\"',\n",
       " 'a_a_x_a',\n",
       " '|',\n",
       " 'a_a_a-n_a.a',\n",
       " 'a_a_a,_a',\n",
       " 'a...',\n",
       " 'n.\"',\n",
       " 'a.a,',\n",
       " 'a-a.a',\n",
       " 'a-a\"',\n",
       " ';',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"x\"',\n",
       " 'a.a.\"',\n",
       " 'a-n',\n",
       " 'x_a_a_a',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'x,',\n",
       " 'a_a_n-a_a.a',\n",
       " 'a_a_a_n-a.a',\n",
       " 'a_a_',\n",
       " '\\\\a',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"n\"',\n",
       " '&a;',\n",
       " '#a',\n",
       " 'a_n_a_n.a',\n",
       " 'a_a_n\"_a.a',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"x\"',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'n_a.a',\n",
       " 'a.a_a',\n",
       " 'a,_a_a_a.a',\n",
       " '\"a\":\"a@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " 'n-n',\n",
       " 'a_a_a_a-a',\n",
       " \"@a'a\",\n",
       " '...',\n",
       " '\"a\".',\n",
       " 'n\"_a_a_a.a',\n",
       " 'a_a,_a_a',\n",
       " 'a&a;\"',\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " 'n.n.n\"',\n",
       " ':a',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"x\"',\n",
       " '~',\n",
       " 'x.',\n",
       " 'a_x_x_a.a',\n",
       " '&#n;a',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '→',\n",
       " 'a_a_n',\n",
       " 'a_a_a_x',\n",
       " 'a_a_a-a_a',\n",
       " 'a-a_a_a_a',\n",
       " 'n_a_n_a.a',\n",
       " 'a_a-n_a_a.a',\n",
       " 'a-a:\"',\n",
       " 'a-a.',\n",
       " 'a-',\n",
       " '--a-a',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"x\"',\n",
       " 'n%',\n",
       " 'a_',\n",
       " '\"a\":\"a_x@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"n\"',\n",
       " 'n,\"a\":\"n\",\"a\":\"a',\n",
       " 'a_a-a_a_a',\n",
       " 'a;\"',\n",
       " 'a:&a',\n",
       " '_a',\n",
       " '\"a\":\"x.x@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"x-x@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"x\"',\n",
       " 'x:',\n",
       " 'n.n.',\n",
       " '\\\\',\n",
       " 'a..',\n",
       " 'a-a.\"',\n",
       " 'a&#n;a&a',\n",
       " 'a\".\"',\n",
       " '$n_a',\n",
       " 'x_x_a_a.a',\n",
       " 'a_x_a_n.a',\n",
       " 'a_a\"',\n",
       " 'a.a:\"',\n",
       " 'a..\"',\n",
       " '__a__',\n",
       " ';\"',\n",
       " '-\"',\n",
       " '\"a\":\"x_x@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"x\"',\n",
       " '\"a\":\"a.x@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " 'n:',\n",
       " 'n-a_a_a_a.a',\n",
       " 'a_x_n_a.a',\n",
       " 'a-\"',\n",
       " '_a_a',\n",
       " \"'\",\n",
       " '&a;a:',\n",
       " '$',\n",
       " '\"a-a\"',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " 'n_a_a_n.a',\n",
       " 'n;',\n",
       " 'a.a.,',\n",
       " 'a...a',\n",
       " 'a-a_a_a_n.a',\n",
       " 'a#\"',\n",
       " '^',\n",
       " \"'a',\",\n",
       " '#',\n",
       " '\"a:',\n",
       " '\"#a\"',\n",
       " 'x.n',\n",
       " 'n.n.n,',\n",
       " 'n.n\"',\n",
       " 'a_a_n.n_a.a',\n",
       " 'a_a_a._a.a',\n",
       " 'a_a_a,_n.n.a',\n",
       " 'a_a,_n_a.a',\n",
       " 'a:n',\n",
       " 'a++',\n",
       " '_',\n",
       " '.a-a',\n",
       " ',a',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"x\"',\n",
       " '–',\n",
       " 'n_a_a.a',\n",
       " 'a_a_x_x.a',\n",
       " 'a_a_n.a',\n",
       " 'a_a_n-n_a.a',\n",
       " 'a_a.\"',\n",
       " 'a\\\\a',\n",
       " 'a.a.a\"',\n",
       " 'a-a-a\"',\n",
       " 'a&a_a_a_a.a',\n",
       " '..',\n",
       " '.*',\n",
       " '&#n;a&#n;\"',\n",
       " '\"a\":\"x.a@a.a\",\"a\":\"n\"',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"x\",\"a\":\"x\",\"a\":',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"x\"',\n",
       " 'x_a.a',\n",
       " 'n-a',\n",
       " 'a_n_a_x.a',\n",
       " 'a_a_x_n.a',\n",
       " 'a_a_n-a-n_a.a',\n",
       " 'a_a.',\n",
       " 'a_a-a-a_a_a.a',\n",
       " 'a_a,',\n",
       " 'a-x',\n",
       " '\\\\n',\n",
       " \"'a'.\",\n",
       " '!',\n",
       " '“a',\n",
       " 'x:\"',\n",
       " 'n:\"',\n",
       " 'n.n.n.\"',\n",
       " 'a_n_a_n',\n",
       " 'a_n_',\n",
       " 'a_n\"_a_a',\n",
       " 'a_a_n_n.a',\n",
       " 'a_a_n.n\"_a.a',\n",
       " 'a_a_n%_a.a',\n",
       " 'a_a_a_a,a.a',\n",
       " 'a:a,',\n",
       " 'a::a',\n",
       " 'a.a.a.a',\n",
       " 'a-a-a_a_a_a.a',\n",
       " 'a-a&a',\n",
       " 'a,&a',\n",
       " 'a\".',\n",
       " '@a,',\n",
       " '.a.a',\n",
       " \"'a.a'\",\n",
       " '#a-a',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '!a',\n",
       " '!--',\n",
       " 'x_a_a.a',\n",
       " 'n+',\n",
       " 'a_n_n_a.a',\n",
       " 'a_n.n\"_a_a.a',\n",
       " 'a_n%_a_a.a',\n",
       " 'a_a_x',\n",
       " 'a_a_a_n-a',\n",
       " 'a_a_a:_a.a',\n",
       " 'a_a_a,a_a.a',\n",
       " 'a-a.a\"',\n",
       " 'a&#n;',\n",
       " '@x',\n",
       " '.a_a',\n",
       " '-a\"',\n",
       " '$n',\n",
       " '\"a.a\"',\n",
       " '\"a\":\"x_a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a_a@a.a\",\"a\":\"n\"',\n",
       " '\"\"',\n",
       " '“a”,',\n",
       " '—',\n",
       " \"x'a\",\n",
       " 'n.n.n.',\n",
       " 'n-a.a',\n",
       " 'n,\"a\":\"n\",\"a\":\"x',\n",
       " 'n%;',\n",
       " 'aé_a_a_a.a',\n",
       " 'a_x_x_x.a',\n",
       " 'a_x_a-a_a.a',\n",
       " 'a_x_',\n",
       " 'a_x-n_a_a.a',\n",
       " 'a_x-a_a_a.a',\n",
       " 'a_a_x-n_a.a',\n",
       " 'a_a_n_x.a',\n",
       " 'a_a_a_n.x.a',\n",
       " 'a_a_a-a.a',\n",
       " 'a_a.a_a_a.a',\n",
       " 'a_a-a_a.a',\n",
       " 'a.a:',\n",
       " 'a.a.a.',\n",
       " 'a.a.:\"',\n",
       " 'a-a_a_n_a.a',\n",
       " 'a-a_a_a.a',\n",
       " 'a-a-a-a',\n",
       " '`a`',\n",
       " '_a_n.a',\n",
       " '_a.x',\n",
       " '_a-a_a.a',\n",
       " '@',\n",
       " '::a',\n",
       " ':-',\n",
       " '.a-a-a',\n",
       " '...a',\n",
       " '-n',\n",
       " '--a-a-a',\n",
       " \"'n'\",\n",
       " '$a_a',\n",
       " 'x.\"',\n",
       " 'n_a_a-a_a.a',\n",
       " 'n_a._a_a.a',\n",
       " 'n:n',\n",
       " 'n.a,',\n",
       " 'n-n-n',\n",
       " 'n%_a_a',\n",
       " 'n\"_a.a',\n",
       " 'a|a',\n",
       " 'a_x_a_x.a',\n",
       " 'a_n_x_a.a',\n",
       " 'a_n-n_a_a.a',\n",
       " 'a_a_x_',\n",
       " 'a_a_n-a_a',\n",
       " 'a_a_a_n-n.a',\n",
       " 'a_a_a_n-a-n.a',\n",
       " 'a_a_a_a_a',\n",
       " 'a_a_a-x_a.a',\n",
       " 'a_a_a-_a.a',\n",
       " 'a-a_a-a_a_a.a',\n",
       " 'a-a_a',\n",
       " 'a-a;',\n",
       " 'a-a-a-a-a',\n",
       " 'a,_a_a_a',\n",
       " 'a&a;,',\n",
       " 'a!_a_a_a.a',\n",
       " '`a',\n",
       " '_n.x.a',\n",
       " '\\\\a+',\n",
       " '@a\"',\n",
       " '.a:\"',\n",
       " '...\"',\n",
       " '\\'a\\'.\"',\n",
       " '&a;a&a;&a',\n",
       " '&a;a&a;\"',\n",
       " '&a;a&a',\n",
       " '&a&a-a',\n",
       " '&&',\n",
       " '#a;',\n",
       " '\"a_a\"',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a.a@a.a\",\"a\":\"n\"',\n",
       " 'x_a_x_a.a',\n",
       " 'n_a_n_a',\n",
       " 'n\\\\',\n",
       " 'n.x_a_a_a.a',\n",
       " 'n.x,',\n",
       " 'n.n.n:\"',\n",
       " 'n.n.a',\n",
       " 'n-a_a_a_a',\n",
       " 'n,n,n',\n",
       " 'a”',\n",
       " 'a_x-x_a_a.a',\n",
       " 'a_n.x_a_a.a',\n",
       " 'a_n.n_a_a.a',\n",
       " 'a_n.a',\n",
       " 'a_n-a_a_a',\n",
       " 'a_a_x_x',\n",
       " 'a_a_x_a-a.a',\n",
       " 'a_a_a_x-a.a',\n",
       " 'a_a_a_a-n.a',\n",
       " 'a_a_a,_n-n.a',\n",
       " 'a_a_a,_n',\n",
       " 'a_a:',\n",
       " 'a_a,_a_',\n",
       " 'a_a,_a,_a.a',\n",
       " 'a_a!_a_a.a',\n",
       " 'a:a\"',\n",
       " 'a:-\"',\n",
       " 'a.a.a.a:',\n",
       " 'a.a.a,',\n",
       " 'a.a&a',\n",
       " 'a._a_n_a.a',\n",
       " 'a._a_a_a',\n",
       " 'a-a_a.a',\n",
       " 'a,_a_a,_a.a',\n",
       " 'a++\"',\n",
       " \"a'.\",\n",
       " 'a&#n;\"',\n",
       " 'a#&a',\n",
       " '^a',\n",
       " '@a-a',\n",
       " '.x',\n",
       " '.a-a:a',\n",
       " '.a\"',\n",
       " '-a,',\n",
       " '-&a;',\n",
       " \"''\",\n",
       " '$a,',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '!a;',\n",
       " '!!',\n",
       " '…',\n",
       " '“a”',\n",
       " '‘a',\n",
       " 'x_x_a_a',\n",
       " 'x_n_a_a.a',\n",
       " 'x.n.n',\n",
       " 'x-a_a_a_a.a',\n",
       " 'n_x',\n",
       " 'n_a_x_a.a',\n",
       " 'n_a_n\"x_a.a',\n",
       " 'n_a_a_x.a',\n",
       " 'n.x',\n",
       " 'n-a-n_a_a_a.a',\n",
       " 'n,n',\n",
       " 'n%_a_a_a.a',\n",
       " 'n\"_a_a_a',\n",
       " 'a`a_a_a_a.a',\n",
       " 'a_x_x_a',\n",
       " 'a_x_a',\n",
       " 'a_n_a_a-a.a',\n",
       " 'a_n-a-n_a_a.a',\n",
       " 'a_n\"_n-a_a.a',\n",
       " 'a_a_n_n',\n",
       " 'a_a_n.n_a',\n",
       " 'a_a_n-n_a',\n",
       " 'a_a_a-a_a-a.a',\n",
       " 'a_a_a-a-a_a.a',\n",
       " 'a_a_a,a_a',\n",
       " 'a_a_a,_a-a.a',\n",
       " 'a_a_a\"',\n",
       " 'a_a_#n_a.a',\n",
       " 'a_a-x_a_a.a',\n",
       " 'a_a-n_a_a',\n",
       " 'a_a,_a_a-a.a',\n",
       " 'a_a,_a.a',\n",
       " 'a_a,_a-a_a.a',\n",
       " 'a\\\\',\n",
       " 'a:n\"',\n",
       " 'a.a.a:',\n",
       " 'a-n.a.n:',\n",
       " 'a-n.a',\n",
       " 'a-a_x_a_a.a',\n",
       " 'a-a_a_a_',\n",
       " 'a-a-a.a',\n",
       " 'a,_a',\n",
       " \"a',\",\n",
       " 'a&a;a&a;',\n",
       " 'a\"\"',\n",
       " '_x',\n",
       " '_n_a.a',\n",
       " '@a.',\n",
       " '.a,',\n",
       " '---',\n",
       " '*.a',\n",
       " '&a-a',\n",
       " '&#n;a.a&#n;',\n",
       " '&#n;',\n",
       " '%',\n",
       " '$n.n_a',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"n\"',\n",
       " '!\"',\n",
       " '‘.',\n",
       " '|\\\\\\\\',\n",
       " 'x_x.a',\n",
       " 'x_n',\n",
       " 'x_a’',\n",
       " 'x_a_n_a.a',\n",
       " 'x.n.n\"',\n",
       " 'x.a.a\"',\n",
       " 'x-a',\n",
       " 'x%',\n",
       " 'x\";',\n",
       " 'x\",\"a\":\"a\",\"a\":\"a\"',\n",
       " 'x\",\"a\":\"a',\n",
       " 'n|',\n",
       " 'n_a_a._a.a',\n",
       " 'n.x;',\n",
       " 'n.n.n.n\"',\n",
       " 'n.n.n-x',\n",
       " 'n.n.\"',\n",
       " 'n.n+',\n",
       " \"n'a\",\n",
       " 'a’:',\n",
       " 'a_x_x_x',\n",
       " 'a_x_a_a-a.a',\n",
       " 'a_x-a_a_a',\n",
       " 'a_n°_a_a.a',\n",
       " 'a_n_a._a.a',\n",
       " 'a_n\"_x_a.a',\n",
       " 'a_n\"_a_n.a',\n",
       " 'a_a_n_x',\n",
       " 'a_a_n.x_a.a',\n",
       " 'a_a_a_x.x.n.a',\n",
       " 'a_a_a_n.n',\n",
       " 'a_a_a_n-x.a',\n",
       " 'a_a_a_n-n',\n",
       " 'a_a_a_a,x.a',\n",
       " 'a_a_a_a,n.a',\n",
       " 'a_a_a_\"a.a',\n",
       " 'a_a_a-x-a_a.a',\n",
       " 'a_a_a-a_x.a',\n",
       " 'a_a_a-a_n.a',\n",
       " 'a_a_a,a_a,a.a',\n",
       " 'a_a-a_a_a-a.a',\n",
       " 'a_a-a_a,_a.a',\n",
       " 'a_a,_x,_a.a',\n",
       " 'a_a,_n_a',\n",
       " 'a_a,_a',\n",
       " 'a^',\n",
       " 'a\\\\a\\\\a',\n",
       " 'a@a_n_a_a.a',\n",
       " 'a:a:',\n",
       " \"a:\\\\a\\\\a'\",\n",
       " 'a:\\\\a',\n",
       " 'a.a;',\n",
       " 'a.a.a.a\"',\n",
       " 'a.a.a.\"',\n",
       " 'a.a._a_a_a.a',\n",
       " \"a.a'a\",\n",
       " 'a.a&#n;',\n",
       " 'a-a_n_a_a.a',\n",
       " 'a-a.a.a\"',\n",
       " 'a-a.a,',\n",
       " 'a-a-x',\n",
       " 'a-a-a_a_a_a',\n",
       " 'a-a-a.a\"',\n",
       " 'a-a-a-a.\"',\n",
       " 'a-a-a,',\n",
       " 'a-a-a&a',\n",
       " 'a,a,',\n",
       " 'a+a',\n",
       " \"a'a.\",\n",
       " \"a'a,\",\n",
       " 'a#a\"',\n",
       " 'a#a',\n",
       " 'a#.a',\n",
       " 'a!!',\n",
       " '_x.a',\n",
       " '_a_a_a.a',\n",
       " '_a.',\n",
       " '^\\\\.n-n',\n",
       " '\\\\x',\n",
       " '\\\\a*',\n",
       " '\\\\.',\n",
       " '\\\\-',\n",
       " ':&a',\n",
       " '..a',\n",
       " '-a_a_a',\n",
       " '-a:\"',\n",
       " '-a.',\n",
       " '--a.',\n",
       " '--a,',\n",
       " ',\"',\n",
       " '**',\n",
       " \"'x'\",\n",
       " \"'n',\",\n",
       " \"'a:\",\n",
       " \"'a-a'\",\n",
       " '&a;&#n;a&#n;',\n",
       " '&a;%',\n",
       " '$n,',\n",
       " '$a:\"',\n",
       " '$a-',\n",
       " '#x;',\n",
       " '\"x\";',\n",
       " '\"x',\n",
       " '\"a:a',\n",
       " '\"a.a\".',\n",
       " '\"a-a-a-a\"',\n",
       " '\"a\";',\n",
       " '\"a\":\"x-a@a.a\",\"a\":\"n\",\"a\":\"n\",\"a\":',\n",
       " '\"a\":\"a-x@a.a\",\"a\":\"',\n",
       " '\"a\":\"a-a@a.a\",\"a\":\"n\"',\n",
       " '\"a\".\"',\n",
       " '\"a\"\"',\n",
       " '\"^n.n.n\"',\n",
       " '\",\"a\":\"',\n",
       " '\",\"a\":',\n",
       " 'x_x_a_a-x.a',\n",
       " 'x_a_x_n.a',\n",
       " 'x_a_n-a_a.a',\n",
       " 'x_a_n',\n",
       " 'x_a_a-a_x.a',\n",
       " 'x_a-a_a_a.a',\n",
       " 'x.a.a',\n",
       " 'n_x.a',\n",
       " 'n_a_n\"_a.a',\n",
       " 'n_a_a_n',\n",
       " 'n_a_a',\n",
       " 'n_a_-a_a.a',\n",
       " 'n_a._a_a',\n",
       " 'n.n:',\n",
       " 'n.n.n.n&a',\n",
       " 'n.n+,',\n",
       " 'n-x_a_a_n',\n",
       " 'n-a_a-a_a_a.a',\n",
       " 'n-',\n",
       " 'n+\"',\n",
       " 'n%,',\n",
       " 'aéa',\n",
       " 'aé_a_a_a',\n",
       " 'aÂ_a_a_a.a',\n",
       " 'aÂ_a.a',\n",
       " 'a\\xa0n',\n",
       " 'a~\"',\n",
       " 'a_x_x_',\n",
       " 'a_x_n.x_a.a',\n",
       " 'a_x_n.n_a',\n",
       " 'a_x_a_n',\n",
       " 'a_x_#n_a.a',\n",
       " 'a_x.a',\n",
       " 'a_n_a_x',\n",
       " 'a_n_a_n.n.a',\n",
       " 'a_n_a-a_a.a',\n",
       " 'a_n-n_a_a',\n",
       " 'a_n-n-n_a_a.a',\n",
       " 'a_n-a_x_a.a',\n",
       " 'a_n-a_a_n.a',\n",
       " 'a_n\"_a_n.n.a',\n",
       " 'a_a_x_n-a.a',\n",
       " 'a_a_x_n',\n",
       " 'a_a_x-x_a.a',\n",
       " 'a_a_n-x_a.a',\n",
       " 'a_a_n\"_a',\n",
       " 'a_a_a_x.n.a',\n",
       " 'a_a_a_a-a-a.a',\n",
       " 'a_a_a_a-a-a',\n",
       " 'a_a_a_#n.a',\n",
       " 'a_a_a-x_a',\n",
       " 'a_a_a-n_n.a',\n",
       " 'a_a_a-n-a_a.a',\n",
       " 'a_a_a,n_a.a',\n",
       " 'a_a_a,_x.a',\n",
       " 'a_a:_a_a.a',\n",
       " 'a_a._a_a.a',\n",
       " 'a_a-n_n_n.n.a',\n",
       " 'a_a-n_a_n',\n",
       " 'a_a-n_a-a_a.a',\n",
       " 'a_a-a_n_a.a',\n",
       " 'a_a-a_n_a',\n",
       " 'a_a-a_a_n.a',\n",
       " 'a_a-a_a-a_a.a',\n",
       " 'a_a-a-n-n_a-a-n-n_a.a',\n",
       " 'a_a-a,_a-a_a.a',\n",
       " 'a_a,a_a_a.a',\n",
       " 'a_a,_n.n_a.a',\n",
       " 'a_a,_a_a-n.a',\n",
       " 'a_a&a',\n",
       " 'a@a_a_a_a.a',\n",
       " 'a.a_a_a,',\n",
       " 'a.a.a.a.a',\n",
       " 'a.a._a_a_a',\n",
       " 'a.a-a.a',\n",
       " 'a-x_a_a_a.a',\n",
       " 'a-n_a_a-a_a.a',\n",
       " 'a-n.\"',\n",
       " 'a-a:a;',\n",
       " 'a-a-a.',\n",
       " 'a,_x_a_a',\n",
       " 'a,_a_',\n",
       " 'a,_a.a',\n",
       " 'a,_a-a_a_a.a',\n",
       " 'a&a_a_a_a',\n",
       " 'a&#n;&a',\n",
       " 'a!!\"',\n",
       " '_n.a',\n",
       " '_n',\n",
       " '_a_n',\n",
       " '_:a:',\n",
       " '@\"',\n",
       " ':a-a',\n",
       " ':.x',\n",
       " ':-\"',\n",
       " '.a.',\n",
       " '.a-a,',\n",
       " '--a\"',\n",
       " '+&a',\n",
       " '\\'\"',\n",
       " '&a;\"',\n",
       " '&#n;a.a.a&#n;\"',\n",
       " '&#n;a-a-a-a&#n;',\n",
       " '&#n;a-a&#n;',\n",
       " '&#n;a&#n;&a',\n",
       " '#n',\n",
       " '\"a_a_a\"',\n",
       " '\"a:a\"',\n",
       " '\"a-a-a\"',\n",
       " '\"a-a\".',\n",
       " '\"a\":\"x@a.a\",\"a\":\"n.n.n.n\",\"a\":\"n.n.n.n\",\"a\":',\n",
       " '\"a\":\"x@a.a\",\"a\":\"a-\"',\n",
       " '\"a\":\"',\n",
       " '⌥',\n",
       " '⇊',\n",
       " '“a&a',\n",
       " '‘x_x’',\n",
       " '–a',\n",
       " 'Đa',\n",
       " '~n',\n",
       " '~a&a;a\"',\n",
       " '~a&a',\n",
       " '~a',\n",
       " '||',\n",
       " '|n',\n",
       " '|_',\n",
       " '|:\"',\n",
       " 'x_x-a\"',\n",
       " 'x_n.\"',\n",
       " 'x_n-a-a',\n",
       " \"x_n',\",\n",
       " 'x_a_a_n-a.a',\n",
       " 'x_a_a_a&a',\n",
       " 'x_a_a_',\n",
       " 'x_a_a-n_a.a',\n",
       " 'x;a-a:x\"',\n",
       " 'x;,',\n",
       " 'x.n.n_n.a',\n",
       " 'x.n.n-a-n,',\n",
       " 'x.n.\"',\n",
       " 'x.n+,',\n",
       " 'x.a-a.a#x.a-a.a-a-a-a\"',\n",
       " 'x...;\"',\n",
       " 'x-x-x-x-x\"',\n",
       " 'x-a_-n_n_a.a',\n",
       " 'x-a:\"',\n",
       " 'x-a.a',\n",
       " 'x-a-n.a\"',\n",
       " 'x,a_a_a,a_a.a',\n",
       " 'x,&a',\n",
       " 'x,\"',\n",
       " 'x+,',\n",
       " 'n°.',\n",
       " 'n°',\n",
       " 'n_a_x_x.a',\n",
       " 'n_a_n\"_a',\n",
       " 'n_a_a_x',\n",
       " 'n_a_a_n.x.a',\n",
       " 'n_a_a_a-a.a',\n",
       " 'n_a_-a_a',\n",
       " 'n_a,_n_a.a',\n",
       " 'n:a-a-a',\n",
       " 'n.x_x_a_a.a',\n",
       " 'n.x_a_a_a',\n",
       " 'n.x_a_a.a',\n",
       " 'n.n_a_a_a.a',\n",
       " 'n.n_a._a._a.a',\n",
       " 'n.n:\"',\n",
       " 'n.n.n.n:n.',\n",
       " 'n.n.n.n:n\"',\n",
       " 'n.n.n.n:n',\n",
       " 'n.n.n.n:a',\n",
       " 'n.n.n.n.',\n",
       " 'n.n.n.n&a;\"',\n",
       " 'n.n.n.a.n.',\n",
       " 'n.n.n.a.n',\n",
       " 'n.n.n,a',\n",
       " 'n.n.n+',\n",
       " 'n.n.a#x-x',\n",
       " 'n.n+.',\n",
       " 'n.n\"_a_a_a.a',\n",
       " 'n.a:\"',\n",
       " 'n.a.',\n",
       " 'n-n-n.\"',\n",
       " 'n-n-n,',\n",
       " 'n-a_a_x_a.a',\n",
       " 'n-a_a_a.a',\n",
       " 'n-a_a_a,_a.a',\n",
       " 'n-a_a_a',\n",
       " 'n-a-a-n.a\"',\n",
       " 'n-a-a-a-a-üa,',\n",
       " 'n,x:',\n",
       " 'n,n,n.n\"',\n",
       " \"n'a.\",\n",
       " \"n'\\\\\",\n",
       " \"n','\",\n",
       " \"n'\",\n",
       " 'n&#n;a',\n",
       " 'n%_a_a_a',\n",
       " 'n#',\n",
       " 'n\"_n_a_a.a',\n",
       " 'n\"_a_a.a',\n",
       " 'n\",\"a\":\"a\\'a\",\"a\":\"a\"',\n",
       " 'n\"\"',\n",
       " 'a：\"',\n",
       " 'a\\u2060—a.a.',\n",
       " 'a…\"',\n",
       " 'a”.\"',\n",
       " 'aấa',\n",
       " 'aêa:\"',\n",
       " 'aéa\"',\n",
       " 'a\\xa0a.\"',\n",
       " 'a\\xa0a',\n",
       " 'a~n',\n",
       " \"a~a','\\\\a'\",\n",
       " 'a|a|a',\n",
       " 'a`\"',\n",
       " 'a`',\n",
       " 'a_x_x',\n",
       " 'a_x_n-a_n-x',\n",
       " 'a_x_a_a-a',\n",
       " 'a_x_a-a_n.a',\n",
       " 'a_x_a,_a.a',\n",
       " 'a_x_a,',\n",
       " 'a_x-x_a_a',\n",
       " 'a_x-n_a_a',\n",
       " 'a_x-n-n_a_a.a',\n",
       " 'a_x-n',\n",
       " 'a_n_n-a_a.a',\n",
       " 'a_n_n\"_a.a',\n",
       " 'a_n_a_n.x.a',\n",
       " 'a_n_a_n-n',\n",
       " 'a_n_a_',\n",
       " 'a_n_a',\n",
       " 'a_n:\"',\n",
       " 'a_n.x_x_a.a',\n",
       " 'a_n.x.a',\n",
       " 'a_n.n_a_x.a',\n",
       " 'a_n.n_a-a_x.a',\n",
       " 'a_n.n\"_a_n',\n",
       " 'a_n.',\n",
       " 'a_n-x_n_a.a',\n",
       " 'a_n-x_a_a.a',\n",
       " 'a_n-n_n\"_a.a',\n",
       " 'a_n-n_a_n.a',\n",
       " 'a_n-n_a_a,a.a',\n",
       " 'a_n-n_a-a_a.a',\n",
       " 'a_n-n_a-a_a',\n",
       " 'a_n-a_n.x_a.a',\n",
       " 'a_n-a_a_x.a',\n",
       " 'a_n-a_a-a_a.a',\n",
       " 'a_n-a_a',\n",
       " 'a_n\"x.n\"x\"_a_a.a',\n",
       " 'a_n\"_n_a.a',\n",
       " 'a_n\"_a_a-a',\n",
       " 'a_n\"_a.a',\n",
       " 'a_a_x_n-n',\n",
       " 'a_a_x-n',\n",
       " 'a_a_x-a_a.a',\n",
       " 'a_a_x,_x.a',\n",
       " 'a_a_n_n-a.a',\n",
       " 'a_a_n_a-a.a',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorization_sub.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa35e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
