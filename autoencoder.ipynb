{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1271dc",
   "metadata": {},
   "source": [
    "<h4>TextCNN</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff269",
   "metadata": {},
   "source": [
    "<h5>Imports</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "470aa940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote_plus\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Input, Dropout\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "import jsonlines\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d237b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=['malicious','normal']\n",
    "for name in file_names:\n",
    "    data=[]\n",
    "    with jsonlines.open('dataset/'+name+'.txt') as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data.append({'request':{'method':'POST', 'uri':line['request']['uri'], 'body':line['request']['body'],'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "            else:\n",
    "                data.append({'request':{'method':'GET', 'uri':line['request']['uri'], 'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "    with jsonlines.open('dataset/'+name+'_clean.txt', mode='w') as writer:\n",
    "        writer.write_all(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c0852",
   "metadata": {},
   "source": [
    "<h4>Load and create datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c294e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a  / a / a / a  { \"a\" = \"a\" }   { \"a-a\": \"a\", \"a\": \"a / a,* / *\", \"a-a\": \"a, a, a\", \"a-a\": \"a / n.n  ( a a n.n; x; x )  a / n.n  ( a, a a )  a / n.n.n.n a / n.n\", \"a\": \"a = x; a = x\" } ' 0\n",
      "b'a   / a / a / a   { \" a \" = \" a \" }   { \" a - a \" :   \" a \" ,   \" a \" :   \" a / a , * / * \" ,   \" a - a \" :   \" a ,   a ,   a \" ,   \" a - a \" :   \" a / n . n   ( a   a   n . n ;   x ;   x )   a / n . n   ( a ,   a   a )   a / n . n . n . n   a / n . n \" ,   \" a \" :   \" a = x ;   a = x \" } ' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 00:43:23.778384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-23 00:43:23.799568: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['dataset/malicious_clean.txt' ,'dataset/normal_clean.txt']\n",
    "data={}\n",
    "for file in file_names:\n",
    "    data[file]=[]\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data[file].append('POST'+' '+line['request']['uri']+' '+line['request']['body']+' '+json.dumps(line['request']['headers']))\n",
    "            else:\n",
    "                data[file].append('GET'+' '+line['request']['uri']+' '+json.dumps(line['request']['headers']))\n",
    "                \n",
    "                \n",
    "normal = data[file_names[1]]\n",
    "malicious = data[file_names[0]]\n",
    "normal_part1 = normal[180000:]\n",
    "normal_part2 = normal[:180000]\n",
    "\n",
    "train_examples = normal_part2\n",
    "test_examples = normal_part1+malicious\n",
    "train_labels = [0] * len(train_examples)\n",
    "test_labels = [0]* len(normal_part1)\n",
    "test_labels.extend([1] * len(malicious))\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),train_examples)), train_labels))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),test_examples)), test_labels))\n",
    "\n",
    "\n",
    "def preprocess_text(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    text = tf.strings.regex_replace(text, '(.)',  r'\\1 ')\n",
    "    return text, label\n",
    "\n",
    "def preprocess_text_substitution(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    " \n",
    "# Map the preprocess function to the dataset\n",
    "train = dataset_train.map(preprocess_text)\n",
    "test = dataset_test.map(preprocess_text)\n",
    "\n",
    "train_sub = dataset_train.map(preprocess_text_substitution)\n",
    "test_sub = dataset_test.map(preprocess_text_substitution)\n",
    "\n",
    "for text, label in train_sub.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "for text, label in train.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9246d4",
   "metadata": {},
   "source": [
    "<h4>Vocabularies</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e08cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 00:43:23.850876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-04-23 00:53:16.487408: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorization = TextVectorization(\n",
    "    max_tokens=1000,\n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=256,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization_sub = TextVectorization(\n",
    "    max_tokens=5000, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=128,\n",
    "    pad_to_max_tokens=True,\n",
    "    standardize=\"lower\"\n",
    ")\n",
    "\n",
    "vectorization.adapt(train.map(lambda x, y: x))\n",
    "vectorization_sub.adapt(train_sub.map(lambda x, y: x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ffdfb",
   "metadata": {},
   "source": [
    "<h4>Save and load vectorization from disk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43d89fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:01:40.649481: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-23 01:01:40.737564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "pickle.dump({'config': vectorization.get_config(),'weights': vectorization.get_weights()}, open(\"vectorization.pkl\", \"wb\"))\n",
    "\n",
    "pickle.dump({'config': vectorization_sub.get_config(), 'weights': vectorization_sub.get_weights()}, open(\"vectorization_sub.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "from_disk = pickle.load(open(\"vectorization.pkl\", \"rb\"))\n",
    "vectorization = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "from_disk_sub = pickle.load(open(\"vectorization_sub.pkl\", \"rb\"))\n",
    "vectorization_sub = TextVectorization.from_config(from_disk_sub['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization_sub.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization_sub.set_weights(from_disk_sub['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cf1bf",
   "metadata": {},
   "source": [
    "<h4>Autoencoder</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0531230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:02:31.433838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [180000]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 46s 8ms/step - loss: 0.7587\n",
      "Epoch 2/10\n",
      "5625/5625 [==============================] - 42s 7ms/step - loss: 0.4940\n",
      "Epoch 3/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4653\n",
      "Epoch 4/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4502\n",
      "Epoch 5/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4398\n",
      "Epoch 6/10\n",
      "5625/5625 [==============================] - 43s 8ms/step - loss: 0.4331\n",
      "Epoch 7/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4285\n",
      "Epoch 8/10\n",
      "5625/5625 [==============================] - 39s 7ms/step - loss: 0.4254\n",
      "Epoch 9/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4235\n",
      "Epoch 10/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 0.4203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c97264cd0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 4)\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), vectorization(text)\n",
    "\n",
    "train_auto = train_sub.map(autoencoder_processing)\n",
    "\n",
    "train_auto = train_auto.batch(32)\n",
    "# Define the autoencoder model\n",
    "input_layer = tf.keras.layers.Input(shape=(256,))\n",
    "encoder = tf.keras.layers.Dense(256, activation='relu')(input_layer)\n",
    "encoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(64, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(256, activation='relu')(decoder)\n",
    "autoencoder = tf.keras.models.Model(input_layer, decoder)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam',  loss=losses.MeanSquaredError())\n",
    "autoencoder.fit(train_auto, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85f91fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.fit(train_auto, epochs=10)\n",
    "autoencoder.save('autoencoder/my_model')\n",
    "autoencoder = tf.keras.models.load_model('autoencoder/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9868826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/3685 [..............................] - ETA: 30s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:10:41.067879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype string\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 24s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), label\n",
    "test_auto = test_sub.map(autoencoder_processing)\n",
    "test_auto = test_auto.batch(32)\n",
    "reconsturctions =  autoencoder.predict(test_auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05b15cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:11:06.176232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [117899]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "def get_data(x, y):\n",
    "  return x\n",
    "\n",
    "# Use the map() function to extract the labels\n",
    "dataset_tmp = test_auto.map(get_data)\n",
    "\n",
    "# Convert the labels dataset to a NumPy array\n",
    "tmp = np.concatenate(list(dataset_tmp.as_numpy_iterator()))\n",
    "mse = tf.keras.losses.mean_squared_error(tmp, reconsturctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c01d3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(map(lambda x: 0 if x.numpy()<0.09 else 1, list(mse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "073354ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:28:53.801071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype string\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    }
   ],
   "source": [
    "actual =test_auto.map(lambda x,y:y)\n",
    "actual = np.concatenate(list(actual.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3daa35e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628199463933316"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(actual,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2db988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
