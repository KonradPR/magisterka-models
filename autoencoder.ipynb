{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a1271dc",
   "metadata": {},
   "source": [
    "<h4>Autoencoder</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecff269",
   "metadata": {},
   "source": [
    "<h5>Imports</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470aa940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:52:36.537767: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-16 19:52:36.580711: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 19:52:37.159378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse, parse_qs, urlencode, urlunparse, unquote_plus\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Input, Dropout, Conv1D\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "import jsonlines\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from tensorflow.python.profiler import profiler_v2 as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d237b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names=['malicious','normal']\n",
    "for name in file_names:\n",
    "    data=[]\n",
    "    with jsonlines.open('dataset/'+name+'.txt') as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data.append({'request':{'method':'POST', 'uri':line['request']['uri'], 'body':line['request']['body'],'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "            else:\n",
    "                data.append({'request':{'method':'GET', 'uri':line['request']['uri'], 'headers':line['request']['headers']},'metadata':line['metdata']})\n",
    "    with jsonlines.open('dataset/'+name+'_clean.txt', mode='w') as writer:\n",
    "        writer.write_all(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c0852",
   "metadata": {},
   "source": [
    "<h4>Load and create datasets</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c294e6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:52:52.281797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:52.328630: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:52.328677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:52.330160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:52.330216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:52.330235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:53.002439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:53.002647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:53.002656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-16 19:52:53.002684: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 19:52:53.002715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'a  / a / a / a  { \"a\" = \"a\" }   { \"a-a\": \"a\", \"a\": \"a / a,* / *\", \"a-a\": \"a, a, a\", \"a-a\": \"a / n.n  ( a a n.n; x; x )  a / n.n  ( a, a a )  a / n.n.n.n a / n.n\", \"a\": \"a = x; a = x\" } ' 0\n",
      "b'a   / a / a / a   { \" a \" = \" a \" }   { \" a - a \" :   \" a \" ,   \" a \" :   \" a / a , * / * \" ,   \" a - a \" :   \" a ,   a ,   a \" ,   \" a - a \" :   \" a / n . n   ( a   a   n . n ;   x ;   x )   a / n . n   ( a ,   a   a )   a / n . n . n . n   a / n . n \" ,   \" a \" :   \" a = x ;   a = x \" } ' 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:52:54.282347: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-05-16 19:52:54.302591: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int32 and shape [180000]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "file_names = ['dataset/malicious_clean.txt' ,'dataset/normal_clean.txt']\n",
    "data={}\n",
    "for file in file_names:\n",
    "    data[file]=[]\n",
    "    with jsonlines.open(file) as reader:\n",
    "        for line in reader:\n",
    "            if line['request']['method'] == 'POST':\n",
    "                data[file].append('POST'+' '+line['request']['uri']+' '+line['request']['body']+' '+json.dumps(line['request']['headers']))\n",
    "            else:\n",
    "                data[file].append('GET'+' '+line['request']['uri']+' '+json.dumps(line['request']['headers']))\n",
    "                \n",
    "                \n",
    "normal = data[file_names[1]]\n",
    "malicious = data[file_names[0]]\n",
    "normal_part1 = normal[180000:]\n",
    "normal_part2 = normal[:180000]\n",
    "\n",
    "train_examples = normal_part2\n",
    "test_examples = normal_part1+malicious\n",
    "train_labels = [0] * len(train_examples)\n",
    "test_labels = [0]* len(normal_part1)\n",
    "test_labels.extend([1] * len(malicious))\n",
    "\n",
    "dataset_train = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),train_examples)), train_labels))\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((list(map(lambda x: unquote_plus(x),test_examples)), test_labels))\n",
    "\n",
    "\n",
    "def preprocess_text(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    text = tf.strings.regex_replace(text, '(.)',  r'\\1 ')\n",
    "    return text, label\n",
    "\n",
    "def preprocess_text_substitution(text, label):\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text, \"[a-zA-Z]+\", \"a\")\n",
    "    text = tf.strings.regex_replace(text, \"[0-9]+\", \"n\")\n",
    "    text = tf.strings.regex_replace(text, \"(a|n){2,}\", \"x\")\n",
    "    text = tf.strings.regex_replace(text, '[^\\x00-\\x7F]+', '')\n",
    "    punctuation = \"=?/(){}[]<>\"\n",
    "    for p in punctuation:\n",
    "        text = tf.strings.regex_replace(text, \"\\\\\" + p, \" \"+p+\" \")\n",
    "    return text, label\n",
    "\n",
    " \n",
    "# Map the preprocess function to the dataset\n",
    "train = dataset_train.map(preprocess_text)\n",
    "test = dataset_test.map(preprocess_text)\n",
    "\n",
    "train_sub = dataset_train.map(preprocess_text_substitution)\n",
    "test_sub = dataset_test.map(preprocess_text_substitution)\n",
    "\n",
    "for text, label in train_sub.take(1):\n",
    "    print(text.numpy(), label.numpy())\n",
    "\n",
    "for text, label in train.take(1):\n",
    "    print(text.numpy(), label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ffdfb",
   "metadata": {},
   "source": [
    "<h4>Save and load vectorization from disk</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d89fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:52:54.351758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-16 19:52:54.480589: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "#pickle.dump({'config': vectorization.get_config(),'weights': vectorization.get_weights()}, open(\"vectorization.pkl\", \"wb\"))\n",
    "\n",
    "#pickle.dump({'config': vectorization_sub.get_config(), 'weights': vectorization_sub.get_weights()}, open(\"vectorization_sub.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "from_disk = pickle.load(open(\"vectorization.pkl\", \"rb\"))\n",
    "vectorization = TextVectorization.from_config(from_disk['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization.set_weights(from_disk['weights'])\n",
    "\n",
    "from_disk_sub = pickle.load(open(\"vectorization_sub.pkl\", \"rb\"))\n",
    "vectorization_sub = TextVectorization.from_config(from_disk_sub['config'])\n",
    "# You have to call `adapt` with some dummy data (BUG in Keras)\n",
    "vectorization_sub.adapt(tf.data.Dataset.from_tensor_slices([\"xyz\"]))\n",
    "vectorization_sub.set_weights(from_disk_sub['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cf1bf",
   "metadata": {},
   "source": [
    "<h4>Autoencoder</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0531230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:52:54.861358: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype int64\n",
      "\t [[{{node Placeholder/_7}}]]\n",
      "2023-05-16 19:52:56.187147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-16 19:52:56.190603: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0xc099b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-16 19:52:56.190632: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-05-16 19:52:56.194845: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-16 19:52:56.340863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-16 19:52:56.478034: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-16 19:52:56.551666: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 43s 7ms/step - loss: 4.3262\n",
      "Epoch 2/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 3.1634\n",
      "Epoch 3/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.9445\n",
      "Epoch 4/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.8225\n",
      "Epoch 5/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.7358\n",
      "Epoch 6/10\n",
      "5625/5625 [==============================] - 41s 7ms/step - loss: 2.6729\n",
      "Epoch 7/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.6250\n",
      "Epoch 8/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.5885\n",
      "Epoch 9/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.5604\n",
      "Epoch 10/10\n",
      "5625/5625 [==============================] - 40s 7ms/step - loss: 2.5378\n",
      "Elapsed time: 402.99103808403015 seconds\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 19:59:37.852001: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_7' with dtype int64\n",
      "\t [[{{node Placeholder/_7}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 39s 7ms/step - loss: 93.9164\n",
      "Epoch 2/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 58.1716\n",
      "Epoch 3/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 52.8472\n",
      "Epoch 4/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 50.2034\n",
      "Epoch 5/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 47.0392\n",
      "Epoch 6/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 45.1486\n",
      "Epoch 7/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 41.8873\n",
      "Epoch 8/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 39.9949\n",
      "Epoch 9/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 40.1368\n",
      "Epoch 10/10\n",
      "5625/5625 [==============================] - 38s 7ms/step - loss: 39.2019\n",
      "Elapsed time: 379.51816868782043 seconds\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(1000, 4)\n",
    "flatten_layer = tf.keras.layers.Flatten()\n",
    "\n",
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), vectorization(text)\n",
    "\n",
    "def sub_processing(text, label):\n",
    "    return  vectorization_sub(text), vectorization_sub(text)\n",
    "\n",
    "def processing(text, label):\n",
    "    return  vectorization(text), vectorization(text)\n",
    "\n",
    "train_auto_sub = train_sub.map(sub_processing)\n",
    "train_auto = train.map(processing)\n",
    "\n",
    "train_auto = train_auto.batch(32)\n",
    "train_auto_sub = train_auto_sub.batch(32)\n",
    "\n",
    "input_layer = tf.keras.layers.Input(shape=(256,))\n",
    "encoder = tf.keras.layers.Dense(256, activation='relu')(input_layer)\n",
    "encoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "encoder = tf.keras.layers.Dense(64, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(128, activation='relu')(encoder)\n",
    "decoder = tf.keras.layers.Dense(256, activation='relu')(decoder)\n",
    "autoencoder = tf.keras.models.Model(input_layer, decoder)\n",
    "\n",
    "input_layer_sub = tf.keras.layers.Input(shape=(128,))\n",
    "encoder_sub = tf.keras.layers.Dense(128, activation='relu')(input_layer_sub)\n",
    "encoder_sub = tf.keras.layers.Dense(64, activation='relu')(encoder_sub)\n",
    "encoder_sub = tf.keras.layers.Dense(32, activation='relu')(encoder_sub)\n",
    "decoder_sub = tf.keras.layers.Dense(64, activation='relu')(encoder_sub)\n",
    "decoder_sub = tf.keras.layers.Dense(128, activation='relu')(decoder_sub)\n",
    "autoencoder_sub = tf.keras.models.Model(input_layer_sub, decoder_sub)\n",
    "\n",
    "# Compile and train the model\n",
    "autoencoder.compile(optimizer='adam',  loss=losses.MeanSquaredError())\n",
    "autoencoder_sub.compile(optimizer='adam',  loss=losses.MeanSquaredError())\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "autoencoder.fit(train_auto, epochs=10)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "start_time = time.time()\n",
    "autoencoder_sub.fit(train_auto_sub, epochs=10)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85f91fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: autoencoder/my_model/assets\n",
      "INFO:tensorflow:Assets written to: autoencoder_sub/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.fit(train_auto, epochs=10)\n",
    "autoencoder.save('autoencoder/my_model')\n",
    "autoencoder_sub.save('autoencoder_sub/my_model')\n",
    "\n",
    "autoencoder = tf.keras.models.load_model('autoencoder/my_model')\n",
    "autoencoder_sub = tf.keras.models.load_model('autoencoder_sub/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9868826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8/3685 [..............................] - ETA: 30s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:10:41.067879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype string\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3685/3685 [==============================] - 24s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "def autoencoder_processing(text, label):\n",
    "    return  vectorization(text), label\n",
    "def autoencoder_processing_sub(text, label):\n",
    "    return  vectorization_sub(text), label\n",
    "\n",
    "test_auto = test.map(autoencoder_processing)\n",
    "test_auto = test_auto.batch(32)\n",
    "test_auto_sub = test_sub.map(autoencoder_processing_sub)\n",
    "test_auto_sub = test_auto_sub.batch(32)\n",
    "\n",
    "reconsturctions =  autoencoder.predict(test_auto)\n",
    "reconsturctions_sub =  autoencoder_sub.predict(test_auto_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05b15cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:11:06.176232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [117899]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "def get_data(x, y):\n",
    "  return x\n",
    "\n",
    "# Use the map() function to extract the labels\n",
    "dataset_tmp = test_auto.map(get_data)\n",
    "dataset_tmp_sub = test_auto_sub.map(get_data)\n",
    "\n",
    "# Convert the labels dataset to a NumPy array\n",
    "tmp = np.concatenate(list(dataset_tmp.as_numpy_iterator()))\n",
    "mse = tf.keras.losses.mean_squared_error(tmp, reconsturctions)\n",
    "\n",
    "tmp_sub = np.concatenate(list(dataset_tmp_sub.as_numpy_iterator()))\n",
    "mse_sub = tf.keras.losses.mean_squared_error(tmp_sub, reconsturctions_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c01d3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = list(map(lambda x: 0 if x.numpy()<0.09 else 1, list(mse)))\n",
    "pred_sub = list(map(lambda x: 0 if x.numpy()<0.09 else 1, list(mse_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "073354ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 01:28:53.801071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype string\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    }
   ],
   "source": [
    "actual =test_auto.map(lambda x,y:y)\n",
    "actual = np.concatenate(list(actual.as_numpy_iterator()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3daa35e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628199463933316"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Metrics\")\n",
    "print(\"f1: \", f1_score(actual,pred))\n",
    "print(\"acc: \", accuracy_score(actual,pred))\n",
    "print(\"prec: \", precision_score(actual,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478a03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metrics sub\")\n",
    "print(\"f1: \", f1_score(actual,pred_sub))\n",
    "print(\"acc: \", accuracy_score(actual,pred_sub))\n",
    "print(\"prec: \", precision_score(actual,pred_sub))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
